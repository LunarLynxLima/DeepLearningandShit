{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "from EncDec import *\n",
    "from DLA3.EncDec.changerollno import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "P = argparse.ArgumentParser()\n",
    "P.add_argument(\"gpu\", type=str)\n",
    "P.add_argument(\"bonus\", type=str)\n",
    "A = P.parse_args()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    Data = DataLoader(dataset=AlteredMNIST(),\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=True,\n",
    "                      num_workers=2,\n",
    "                      drop_last=True,\n",
    "                      pin_memory=True)\n",
    "    E = Encoder()\n",
    "    D = Decoder()\n",
    "    \n",
    "    L = [AELossFn(),\n",
    "         VAELossFn()]\n",
    "    \n",
    "    O = torch.optim.Adam(ParameterSelector(), lr=LEARNING_RATE)\n",
    "    \n",
    "    print(\"Training Encoder: {}, Decoder: {} on Modified MNIST dataset in AE training paradigm\".format(\n",
    "        E.__class__.__name__,\n",
    "        D.__class__.__name__,\n",
    "    ))\n",
    "    AETrainer(Data,\n",
    "              E,\n",
    "              D,\n",
    "              L[0],\n",
    "              O,\n",
    "              A.gpu)\n",
    "    \n",
    "    print(\"Training Encoder: {}, Decoder: {} on Modified MNIST dataset in VAE training paradigm\".format(\n",
    "        E.__class__.__name__,\n",
    "        D.__class__.__name__,\n",
    "    ))\n",
    "    VAETrainer(Data,\n",
    "               E,\n",
    "               D,\n",
    "               L[1],\n",
    "               O,\n",
    "               A.gpu)\n",
    "    \n",
    "    print(\"AE, VAE Training Complete\")\n",
    "    \n",
    "    if A.bonus == \"T\":\n",
    "        CL = CVAELossFn()\n",
    "        CVAE_Trainer(Data,\n",
    "                     E,\n",
    "                     D,\n",
    "                     CL,\n",
    "                     O)\n",
    "    else:\n",
    "        print(\"Bonus Question not done\")\n",
    "        \n",
    "    AE_Pipeline = AE_TRAINED(gpu=False)\n",
    "    VAE_Pipeline = VAE_TRAINED(gpu=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" For TAs Only \"\"\"\n",
    "    \n",
    "    # TestData = TestMNIST()\n",
    "    # AESSIM, VAESSIM = [], []\n",
    "    # AEPSNR, VAEPSNR = [], []\n",
    "    # for sample, original in TestData:\n",
    "    #     AESSIM.append(AE_Pipeline.from_path(sample, original, type=\"SSIM\"))\n",
    "    #     VAESSIM.append(VAE_Pipeline.from_path(sample, original, type=\"SSIM\"))\n",
    "    #     AEPSNR.append(AE_Pipeline.from_path(sample, original, type=\"PSNR\"))\n",
    "    #     VAEPSNR.append(VAE_Pipeline.from_path(sample, original, type=\"PSNR\"))\n",
    "    \n",
    "    # print(\"SSIM Score of AutoEncoder Training paradigm: {}\".format(sum(AESSIM)/len(AESSIM)))\n",
    "    # print(\"SSIM Score of Variational AutoEncoder Training paradigm: {}\".format(sum(VAESSIM)/len(VAESSIM)))\n",
    "    # print(\"PSNR Score of AutoEncoder Training paradigm: {}\".format(sum(AEPSNR)/len(AEPSNR)))\n",
    "    # print(\"PSNR Score of Variational AutoEncoder Training paradigm: {}\".format(sum(VAEPSNR)/len(VAEPSNR)))\n",
    "    \n",
    "    # if A.bonus == \"T\":\n",
    "    #     Generator = CVAE_Generator()\n",
    "    #     for _ in range(24):\n",
    "    #         Generator.save_image(digit=random.choice(range(10)), save_path=SAVEPATH)\n",
    "    #\n",
    "    #     print(\"Similarity Score for generated data is: {}\".format(GeneratorSimilarity(SAVEPATH)))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
