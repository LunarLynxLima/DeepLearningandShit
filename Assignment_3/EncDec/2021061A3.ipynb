{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlteredMNIST:\n",
    "    \"\"\"\n",
    "    dataset description:\n",
    "    \n",
    "    X_I_L.png\n",
    "    X: {aug=[augmented], clean=[clean]}\n",
    "    I: {Index range(0,60000)}\n",
    "    L: {Labels range(10)}\n",
    "    \n",
    "    Write code to load Dataset\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class Encoder:\n",
    "    \"\"\"\n",
    "    Write code for Encoder ( Logits/embeddings shape must be [batch_size,channel,height,width] )\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class Decoder:\n",
    "    \"\"\"\n",
    "    Write code for decoder here ( Output image shape must be same as Input image shape i.e. [batch_size,1,28,28] )\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class AELossFn:\n",
    "    \"\"\"\n",
    "    Loss function for AutoEncoder Training Paradigm\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class VAELossFn:\n",
    "    \"\"\"\n",
    "    Loss function for Variational AutoEncoder Training Paradigm\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def ParameterSelector(E, D):\n",
    "    \"\"\"\n",
    "    Write code for selecting parameters to train\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class AETrainer:\n",
    "    \"\"\"\n",
    "    Write code for training AutoEncoder here.\n",
    "    \n",
    "    for each 10th minibatch use only this print statement\n",
    "    print(\">>>>> Epoch:{}, Minibatch:{}, Loss:{}, Similarity:{}\".format(epoch,minibatch,loss,similarity))\n",
    "    \n",
    "    for each epoch use only this print statement\n",
    "    print(\"----- Epoch:{}, Loss:{}, Similarity:{}\")\n",
    "    \n",
    "    After every 5 epochs make 3D TSNE plot of logits of whole data and save the image as AE_epoch_{}.png\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class VAETrainer:\n",
    "    \"\"\"\n",
    "    Write code for training Variational AutoEncoder here.\n",
    "    \n",
    "    for each 10th minibatch use only this print statement\n",
    "    print(\">>>>> Epoch:{}, Minibatch:{}, Loss:{}, Similarity:{}\".format(epoch,minibatch,loss,similarity))\n",
    "    \n",
    "    for each epoch use only this print statement\n",
    "    print(\"----- Epoch:{}, Loss:{}, Similarity:{}\")\n",
    "    \n",
    "    After every 5 epochs make 3D TSNE plot of logits of whole data and save the image as VAE_epoch_{}.png\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class AE_TRAINED:\n",
    "    \"\"\"\n",
    "    Write code for loading trained Encoder-Decoder from saved checkpoints for Autoencoder paradigm here.\n",
    "    use forward pass of both encoder-decoder to get output image.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    def from_path(sample, original, type):\n",
    "        \"Compute similarity score of both 'sample' and 'original' and return in float\"\n",
    "        pass\n",
    "\n",
    "class VAE_TRAINED:\n",
    "    \"\"\"\n",
    "    Write code for loading trained Encoder-Decoder from saved checkpoints for Autoencoder paradigm here.\n",
    "    use forward pass of both encoder-decoder to get output image.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    def from_path(sample, original, type):\n",
    "        \"Compute similarity score of both 'sample' and 'original' and return in float\"\n",
    "        pass\n",
    "\n",
    "class CVAELossFn():\n",
    "    \"\"\"\n",
    "    Write code for loss function for training Conditional Variational AutoEncoder\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class CVAE_Trainer:\n",
    "    \"\"\"\n",
    "    Write code for training Conditional Variational AutoEncoder here.\n",
    "    \n",
    "    for each 10th minibatch use only this print statement\n",
    "    print(\">>>>> Epoch:{}, Minibatch:{}, Loss:{}, Similarity:{}\".format(epoch,minibatch,loss,similarity))\n",
    "    \n",
    "    for each epoch use only this print statement\n",
    "    print(\"----- Epoch:{}, Loss:{}, Similarity:{}\")\n",
    "    \n",
    "    After every 5 epochs make 3D TSNE plot of logits of whole data and save the image as CVAE_epoch_{}.png\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class CVAE_Generator:\n",
    "    \"\"\"\n",
    "    Write code for loading trained Encoder-Decoder from saved checkpoints for Conditional Variational Autoencoder paradigm here.\n",
    "    use forward pass of both encoder-decoder to get output image conditioned to the class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def save_image(digit, save_path):\n",
    "        pass\n",
    "\n",
    "def peak_signal_to_noise_ratio(img1, img2):\n",
    "    if img1.shape[0] != 1: raise Exception(\"Image of shape [1,H,W] required.\")\n",
    "    img1, img2 = img1.to(torch.float64), img2.to(torch.float64)\n",
    "    mse = img1.sub(img2).pow(2).mean()\n",
    "    if mse == 0: return float(\"inf\")\n",
    "    else: return 20 * torch.log10(255.0/torch.sqrt(mse)).item()\n",
    "\n",
    "def structure_similarity_index(img1, img2):\n",
    "    if img1.shape[0] != 1: raise Exception(\"Image of shape [1,H,W] required.\")\n",
    "    # Constants\n",
    "    window_size, channels = 11, 1\n",
    "    K1, K2, DR = 0.01, 0.03, 255\n",
    "    C1, C2 = (K1*DR)**2, (K2*DR)**2\n",
    "\n",
    "    window = torch.randn(11)\n",
    "    window = window.div(window.sum())\n",
    "    window = window.unsqueeze(1).mul(window.unsqueeze(0)).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channels)\n",
    "    mu12 = mu1.pow(2).mul(mu2.pow(2))\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size//2, groups=channels) - mu1.pow(2)\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size//2, groups=channels) - mu2.pow(2)\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=window_size//2, groups=channels) - mu12\n",
    "\n",
    "\n",
    "    SSIM_n = (2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denom = ((mu1**2 + mu2**2 + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return torch.clamp((1 - SSIM_n / (denom + 1e-8)), min=0.0, max=1.0).mean().item()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
